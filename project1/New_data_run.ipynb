{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CCD_implementation import LogRegCCD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, balanced_accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from preprocessing import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''\n",
    "df = pd.read(path)\n",
    "# Placeholder for users own preprocessing. Remember to rename y column as \"target\".\n",
    "X, y, X_train, X_test, y_train, y_test = split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for comparison of both algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lr_ccd(X_train, y_train, X_test, y_test, max_iter=50, weights = True):\n",
    "    model=LogRegCCD()\n",
    "    best_lambda=model.plot(X=X_train, y=y_train, max_iter=max_iter,weights=weights,measure='balanced accuracy')\n",
    "    model.plot_coefficients(X=X_train, y=y_train, max_iter=max_iter,weights=weights)\n",
    "    print(\"Best lambda\",best_lambda)\n",
    "    model.fit(X_train, y_train, max_iter=max_iter,weights=weights,user_lambda=best_lambda, fit_intercept=True,plots = True)\n",
    "\n",
    "    \n",
    "    y_proba = model.predict_proba(X_test)\n",
    "\n",
    "    roc_auc = model.ROC_AUC(y_test, y_proba)\n",
    "    prc_auc = model.PR_AUC(y_test, y_proba)\n",
    "    f_score = model.validate(X_test,y_test, 'F-score')\n",
    "    balanced_accuracy = model.validate(X_test,y_test, 'balanced accuracy')\n",
    "\n",
    "    print(\"Performance on test set for custom logistic regression:\")\n",
    "    print(\"ROC AUC:\", roc_auc)\n",
    "    print(\"Recall-Precision AUC:\", prc_auc)\n",
    "    print(\"F-score:\", f_score)\n",
    "    print(\"Balanced Accuracy:\", balanced_accuracy)\n",
    "\n",
    "    print(\"Coefficient values obtained (custom model):\")\n",
    "    print(\"Coefficients:\", model.B)\n",
    "    print(\"Intercept:\", model.B0)\n",
    "\n",
    "    return model.B\n",
    "\n",
    "def evaluate_lr_sklearn(X_train, y_train, X_test, y_test):\n",
    "    model_sklearn = LogisticRegression(penalty=None)\n",
    "    model_sklearn.fit(X_train, y_train)\n",
    "\n",
    "    y_proba_sklearn = model_sklearn.predict_proba(X_test)[:, 1]\n",
    "    y_pred_sklearn = model_sklearn.predict(X_test)\n",
    "\n",
    "    roc_auc_sklearn = roc_auc_score(y_test, y_proba_sklearn)\n",
    "    prc_auc_sklearn = average_precision_score(y_test, y_proba_sklearn)\n",
    "    f_score_sklearn = f1_score(y_test, y_pred_sklearn)\n",
    "    balanced_accuracy_sklearn = balanced_accuracy_score(y_test, y_pred_sklearn)\n",
    "\n",
    "    print(\"Performance on test set for sklearn logistic regression:\")\n",
    "    print(\"ROC AUC:\", roc_auc_sklearn)\n",
    "    print(\"Recall-Precision AUC:\", prc_auc_sklearn)\n",
    "    print(\"F-score:\", f_score_sklearn)\n",
    "    print(\"Balanced Accuracy:\", balanced_accuracy_sklearn)\n",
    "\n",
    "    print(\"Coefficient values obtained (sklearn):\")\n",
    "    print(\"Coefficients:\", model_sklearn.coef_)\n",
    "    print(\"Intercept:\", model_sklearn.intercept_)\n",
    "    return model_sklearn.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_coefficients(coef_ccd, coef_sk, epsilon=0.01):\n",
    "    coef1 = np.array(coef_ccd)\n",
    "    coef2 = np.array(coef_sk)\n",
    "    norm_coef1 = np.linalg.norm(coef1, axis=0)\n",
    "    norm_coef2 = np.linalg.norm(coef2, axis=0)\n",
    "    avg_norm1 = np.mean(norm_coef1)\n",
    "    avg_norm2 = np.mean(norm_coef2)\n",
    "    small_coef1 = np.sum(np.abs(coef1) < epsilon)\n",
    "    small_coef2 = np.sum(np.abs(coef2) < epsilon)\n",
    "\n",
    "    print(f\"Average norm of coefficients from model ccd: {avg_norm1:.4f}\")\n",
    "    print(f\"Average norm of coefficients from model sk: {avg_norm2:.4f}\")\n",
    "    print(f\"Number of coefficients smaller than {epsilon} in model ccd: {small_coef1}\")\n",
    "    print(f\"Number of coefficients smaller than {epsilon} in model sk: {small_coef2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_ccd=evaluate_lr_ccd(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_sk=evaluate_lr_sklearn(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_coefficients(coef_ccd, coef_sk, epsilon=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= LogRegCCD().fit(X_train,y_test)\n",
    "model.validate(X_test,y_test, measure = \"F-score\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
